import pandas as pd         # ãƒ‡ãƒ¼ã‚¿æ“ä½œç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import numpy as np         # æ•°å€¤è¨ˆç®—ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import os                  # OSæ“ä½œç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from glob import glob      # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ“ä½œç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

# è¨­å®š
input_dir = "hand_data"      # CSVãƒ•ã‚©ãƒ«ãƒ€
output_path = "dataset.npy"  # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
skip_seconds = 5             # æœ€åˆã®5ç§’ã‚’ã‚¹ã‚­ãƒƒãƒ—

# ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†ã™ã‚‹é–¢æ•°
def load_and_preprocess_csv(file_path):
    df = pd.read_csv(file_path)

    # æœ€åˆã®5ç§’ã‚¹ã‚­ãƒƒãƒ—
    start_time = pd.to_datetime(df["timestamp"].iloc[0])
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df = df[df["timestamp"] > start_time + pd.Timedelta(seconds=skip_seconds)]

    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ã‚’å–å¾—ï¼ˆå°æ–‡å­—ã«å¯¾å¿œï¼‰
    coords = df.filter(regex="(x|y|z)\d+").values
    if coords.size == 0:
        raise ValueError(f"âŒ åº§æ¨™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

    normalized_frames = []
    for frame in coords.reshape(-1, 21, 3):
        wrist = frame[0]
        rel = frame - wrist  # æ‰‹é¦–åŸç‚¹åŒ–

        # 1ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ã‚¹ã‚±ãƒ¼ãƒ«æ­£è¦åŒ–
        scale = np.linalg.norm(rel, axis=1).max()
        if scale > 0:
            rel /= scale

        normalized_frames.append(rel.flatten())

    return np.array(normalized_frames)

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
files = glob(os.path.join(input_dir, "*.csv"))
if not files:
    raise FileNotFoundError(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}")

data_by_class = {}
for f in files:
    class_name = os.path.splitext(os.path.basename(f))[0]  # Rock, Paper, Scissors
    coords = load_and_preprocess_csv(f)
    if class_name not in data_by_class:
        data_by_class[class_name] = []
    data_by_class[class_name].append(coords)

# ã‚¯ãƒ©ã‚¹é–“ã§ãƒ‡ãƒ¼ã‚¿æ•°ã‚’æƒãˆã‚‹
min_len = min(min(len(c) for c in data_by_class[k]) for k in data_by_class)
print(f"ğŸ“ å„ã‚¯ãƒ©ã‚¹ {min_len} ã‚µãƒ³ãƒ—ãƒ«ã«çµ±ä¸€")

X, y = [], []
for class_name, datasets in data_by_class.items():
    class_data = np.vstack([c[:min_len] for c in datasets])
    X.append(class_data)
    y.append(np.full(len(class_data), class_name))

X = np.vstack(X)
y = np.concatenate(y)

np.save(output_path, {"X": X, "y": y})
print(f"âœ… dataset saved to {output_path}")
print(f"   X shape = {X.shape}, y shape = {y.shape}")
print(f"   classes = {list(data_by_class.keys())}")
